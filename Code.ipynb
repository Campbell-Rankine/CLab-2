{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc739d8b-40b8-47c2-9ee5-f06dd50da7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campb\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\campb\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn as sk #general imports, initial data preprocessing/OS stuff\n",
    "import os\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim #Neural network imports, multiply data etc\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import torch.nn.functional as F #Neural Network used in Comp4660 at ANU\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from pathlib import Path\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.preprocessing import MinMaxScaler #normalize data\n",
    "from sklearn.metrics import confusion_matrix #analysis\n",
    "from torchvision import transforms\n",
    "from random import shuffle\n",
    "import itertools\n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7217330d-48d4-4376-bd3a-8c0b26177e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - GLOBALS - ###\n",
    "\n",
    "DPS = '/Users/campb/Documents/Comp4528/CLab-2/Dataset' #Change for marking my computer just isnt great with paths as im on windows\n",
    "\n",
    "folds = 3 #Have to do 3-fold since my computer cannot handle anything else\n",
    "\n",
    "device = T.device('cuda:0' if (T.cuda.is_available())  else 'cpu') #Train on device, no parallel gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a842826b-36af-44e6-8a60-5fd8349c3a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ims = np.load('/Users/campb/Documents/Comp4528/CLab-2/Dataset/kmnist-train-imgs.npz')['arr_0']\n",
    "test_ims = np.load('/Users/campb/Documents/Comp4528/CLab-2/Dataset/kmnist-test-imgs.npz')['arr_0']\n",
    "train_lab = np.load('/Users/campb/Documents/Comp4528/CLab-2/Dataset/kmnist-train-labels.npz')['arr_0']\n",
    "test_lab = np.load('/Users/campb/Documents/Comp4528/CLab-2/Dataset/kmnist-test-labels.npz')['arr_0']\n",
    "val_ims = np.load('/Users/campb/Documents/Comp4528/CLab-2/Dataset/kmnist-val-imgs.npz')['arr_0']\n",
    "val_lab = np.load('/Users/campb/Documents/Comp4528/CLab-2/Dataset/kmnist-val-labels.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09999281-3bbe-4c4f-8e2e-68ba9a1f8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59000, 28, 28) (59000,) (10000, 28, 28) (10000,) (1000, 28, 28) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_ims.shape, train_lab.shape, test_ims.shape, test_lab.shape, val_ims.shape, val_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff4942-8244-44e2-aaf0-8bd9b95895c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import as tensors\n",
    "train = T.from_numpy(np.float32(np.concatenate([train_ims,test_ims]))).to(device)\n",
    "labs = T.from_numpy(np.float32(np.concatenate([train_lab,test_lab]))).to(device)\n",
    "assert(train.shape[0] == labs.shape[0])\n",
    "val_ims = T.from_numpy(np.float32(val_ims)).to(device)\n",
    "val_lab = T.from_numpy(np.float32(val_lab)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82f883-f00c-4e8e-b05a-22af42ccc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augmentation\n",
    "transform = transforms.Compose([\n",
    "            transforms.Normalize((0.), (1.0)),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomCrop(28, 4) #Random crop image with output size 28 and padding set to 4, default padding is 0 padding\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b64007-9614-43be-8abb-1cf96c8c9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transform(train) #apply transform to train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66850dfb-c28d-4050-9337-9b2e34491962",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ims = transform(val_ims) #apply transform to validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b2b7f-f423-48e0-8f11-10e32a42c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, labs.shape, val_ims.shape, val_lab.shape)\n",
    "\n",
    "### - Model Variables - ###\n",
    "lr = 1e-3\n",
    "bs = (0.9, 0.999)\n",
    "\n",
    "LabNet= nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "    nn.ReLU(), #First layer\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(), #Second layer\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(7*7*64, 1024), #Filter size 64, and we downsample 2x twice so 28/4\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024,10)\n",
    ").to(device)\n",
    "print(LabNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46377fc-f3d8-4037-8834-da44dfa9e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(LabNet.parameters(), lr = lr, betas=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba3646-fc08-4aa4-849e-dd0f38050755",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "\n",
    "#Loss and Accuracy Methods Only need train\n",
    "all_tloss_e = []\n",
    "all_tacc_e = []\n",
    "\n",
    "test_losses = []\n",
    "test_accuracy = []\n",
    "\n",
    "#Setup k-Fold\n",
    "d = list(range(train.shape[0]))\n",
    "shuffle(d) #Data is shuffled\n",
    "d = np.array_split(d, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac61bc5-8c3b-4d74-bf74-049fc1341132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cyclic Learning Rate Scheduler\n",
    "#Cyclic LR Scheduler\n",
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]\n",
    "\n",
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + np.cos(np.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler\n",
    "\n",
    "#sched = CyclicLR(optimizer, cosine(t_max=(620-(620/3)) * 2, eta_min=lr/100)) #Cycled around about 1/10th of the lr\n",
    "\n",
    "#scheduled = cosine(t_max=(620-(620/3)) * 2, eta_min=lr/100)\n",
    "#learning_rates = [scheduled(t, .001) for t in range(int((304-(304/5))) * 4)]\n",
    "#plt.plot(learning_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3760fca-5733-4577-8f12-7ec7c55a9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - train cell - ###\n",
    "for epoch in range(epochs):\n",
    "    fold_acc = []\n",
    "    \n",
    "    fold_loss = []\n",
    "    for i in range(folds-1):\n",
    "        print(\"Current Fold: \" + str(i))\n",
    "        correct_train = 0\n",
    "        total_train = 0 #Add mean accuracy of folds\n",
    "        test = train[d[-i]]\n",
    "        t_lab = labs[d[-i]]\n",
    "        train_i = d[:i] + d[i+1:]\n",
    "        train_set = train[list(itertools.chain.from_iterable(train_i))]\n",
    "        train_lab = labs[list(itertools.chain.from_iterable(train_i))]\n",
    "        \n",
    "        output_train = []\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        for i, im in enumerate(train_set):\n",
    "            if 1 % 100 == 0:\n",
    "                print(\"100 images\")\n",
    "            outs = LabNet(im[None,:].unsqueeze(1)) #forward pass\n",
    "            loss_i = loss(outs, train_lab[i].unsqueeze(-1).long())\n",
    "            \n",
    "            fold_loss.append(loss_i.item()) #append losses to graph\n",
    "            \n",
    "            output_train.append(outs)\n",
    "            \n",
    "            LabNet.zero_grad(set_to_none=True) # Reset Grads\n",
    "            \n",
    "            loss_i.backward()\n",
    "            \n",
    "            optimizer.step() #update weights\n",
    "            \n",
    "            #sched.step() #Step through LR Scheduler\n",
    "            \n",
    "            #check if correct\n",
    "            guess = T.argmax(outs).item()\n",
    "            if guess == train_lab[i].item():\n",
    "                correct_train += 1\n",
    "            total_train += 1\n",
    "        fold_acc.append(correct_train/total_train)\n",
    "        \n",
    "    #Fold level metrics\n",
    "    #Train set accuracy and loss\n",
    "    all_tloss_e.append(np.mean(fold_loss)) #Add mean loss over all folds\n",
    "    all_tacc_e.append(np.mean(fold_acc)) #Add mean fold accuracy to accuracy metric\n",
    "    \n",
    "    #Test-set accuracy\n",
    "    test_total = 0\n",
    "    test_correct = 0\n",
    "    \n",
    "    test_loss = []\n",
    "    \n",
    "    for j, y in enumerate(test):\n",
    "        tout = LabNet(y[None,:].unsqueeze(1))\n",
    "        \n",
    "        test_loss.append(loss(tout, t_lab[j].unsqueeze(-1).long()).item())\n",
    "        guess1 = T.argmax(tout).item()\n",
    "        if guess1 == t_lab[j].item():\n",
    "            test_correct += 1\n",
    "        test_total += 1\n",
    "        \n",
    "    test_accuracy.append(test_correct/test_total)\n",
    "    test_losses.append(np.mean(test_loss))\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        # convert three-column predicted Y values to one column for \n",
    "\n",
    "        print('Epoch [%d/%d] Loss: %.4f  Accuracy: %.2f %%'\n",
    "                % (epoch + 1, epochs, np.mean(fold_loss), np.mean(fold_acc)*100))\n",
    "        print('Testing Loss: %.4f  TestingAccuracy: %.2f %%'\n",
    "                % (np.mean(test_loss), (test_correct/test_total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881987d-d559-4058-8278-0831a6bd7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph of loss over time(Num Epochs)\n",
    "#training loss\n",
    "plt.plot(range(0,(epochs)), all_tloss_e, alpha=0.7, color='tab:red')\n",
    "plt.xlabel('validations')\n",
    "plt.ylabel('CE Loss')\n",
    "plt.title('Graph of Training Loss Over # Epochs')\n",
    "plt.show()\n",
    "#test loss\n",
    "plt.plot(range(0,(epochs)), test_losses, alpha=0.7, color='tab:blue')\n",
    "plt.xlabel('validations')\n",
    "plt.ylabel('CE Loss')\n",
    "plt.title('Graph of Testing loss Over # Epochs')\n",
    "plt.show()\n",
    "#training acc\n",
    "plt.plot(range(0,(epochs)), all_tacc_e, alpha=0.7, color='tab:pink')\n",
    "plt.xlabel('validations')\n",
    "plt.ylabel('CE Loss')\n",
    "plt.title('Graph of Training accuracy Over # Epochs')\n",
    "plt.show()\n",
    "#testing acc\n",
    "plt.plot(range(0,(epochs)), test_accuracy, alpha=0.7, color='tab:green')\n",
    "plt.xlabel('validations')\n",
    "plt.ylabel('CE Loss')\n",
    "plt.title('Graph of Testing accuracy Over # Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a8ce5-06a9-4100-8eb0-62178bff2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle validation set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
